{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicle Traffic Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TfRImiRqVT61",
        "E1yTMY_vjA2d"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNsuvxY1VGdw"
      },
      "source": [
        "# **Vehicle Traffic Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfRImiRqVT61"
      },
      "source": [
        "# **Yolo Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hBnBaWTjDA8"
      },
      "source": [
        "# Resizing images \n",
        " \n",
        "\n",
        "# importing os module \n",
        "import os \n",
        "from PIL import Image\n",
        "# Function to rename multiple files \n",
        "def main(): \n",
        "  for count, filename in enumerate(os.listdir(\"/content/darknet/images_cam2\")):\n",
        "    filename='/content/darknet/images_cam2/' + filename\n",
        "    if (filename.endswith('.jpg')):\n",
        "      print(filename)\n",
        "      image = Image.open(filename)\n",
        "      new_image = image.resize((500, 400))\n",
        "      new_image.save('/content/darknet/images_cam2/resized/'+str(count)+'.jpg')\n",
        "      print(image.size) # Output: (1200, 776)\n",
        "      print(new_image.size) # Output: (400, 400)\n",
        "      \n",
        "\n",
        "# Driver Code \n",
        "if __name__ == '__main__': \n",
        "\t\n",
        "\t# Calling main() function \n",
        "\tmain() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qwrY103jEZh"
      },
      "source": [
        "!cp -r '/content/drive/My Drive/Computer Vision/mini project 1/darknet/' '/content/'\n",
        "%cd /content/darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmSA9EP_jG17"
      },
      "source": [
        "!python process.py -a Images -p 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxMxv1iDjKvM"
      },
      "source": [
        "%%writefile cfg/mask-yolov3.cfg\n",
        "[net]\n",
        "# Testing\n",
        "# batch=64\n",
        "subdivisions=8\n",
        "# Training\n",
        "batch=24\n",
        "subdivisions=2\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.001\n",
        "burn_in=1000\n",
        "max_batches = 500200\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=16\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "###########\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=36\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes=7\n",
        "num=6\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 8\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=36\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes=7\n",
        "num=6\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q69MvZbFjxST"
      },
      "source": [
        "%%writefile cfg/mask-obj.data\n",
        "classes= 7\n",
        "train  = train.txt  \n",
        "valid  = test.txt  \n",
        "names = cfg/mask-obj.names  \n",
        "backup = backup/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0buQjg9Jj0sD"
      },
      "source": [
        "%%writefile cfg/mask-obj.names\n",
        "Bike\n",
        "Bus\n",
        "Car\n",
        "Mini Bus\n",
        "Mini Truck\n",
        "Rickshaw\n",
        "Truck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aquwkh_Aj7p5"
      },
      "source": [
        "**Run the cell below to start training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mA6tsyzj2xi"
      },
      "source": [
        "!./darknet detector train cfg/mask-obj.data cfg/mask-yolov3.cfg darknet53.conv.74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHpo8ysskFaF"
      },
      "source": [
        "# **Yolo Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUnCIZ6NTGQt"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import time \n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from PIL import Image\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pCMU4muZrPV"
      },
      "source": [
        "video_dir='/content/drive/MyDrive/Sproj2/videos/Gulberg_night.mp4'\n",
        "frames_dir='/content/frames_night_gulberg/'\n",
        "resized_frames_dir='/content/resized_night_gulberg/'\n",
        "results_dir='/content/results_night_gulberg/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMEKpVVWgujS"
      },
      "source": [
        "## **Generate frames from video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcgW3y1NZqa1"
      },
      "source": [
        "!rm -rf '/content/resized_night_gulberg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJdxmKUX_mji"
      },
      "source": [
        "# Generate frames from video\n",
        "cap= cv2.VideoCapture(video_dir)\n",
        "i=0\n",
        "!mkdir '/content/frames_night_gulberg/'\n",
        "count=0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    # value of i=1800 to save 1800/5 frames (360 frames)\n",
        "    # if i==1800:\n",
        "    #   break\n",
        "    if count==360:\n",
        "      break\n",
        "    if i>=2700:\n",
        "      if i%5==0:\n",
        "        cv2.imwrite(frames_dir+str(count)+'.jpg',frame)\n",
        "        count+=1\n",
        "    i+=1\n",
        "\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn0J3FM6g2bz"
      },
      "source": [
        "## **Resize images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLDCQ1xUUFE"
      },
      "source": [
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key)] \n",
        "    return sorted(data, key=alphanum_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdczEBWeAqH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4add76-ed14-4565-fd2a-a66833820391"
      },
      "source": [
        "# Resize all the frames to size of (1024,1920,3) from (1080,1920,3)\n",
        "# Pythono3 code to rename multiple \n",
        "# files in a directory or folder \n",
        "\n",
        "# Function to rename multiple files \n",
        "!mkdir '/content/resized_night_gulberg/'\n",
        "def main(): \n",
        "\n",
        "\tfor count, filename in enumerate(sorted_alphanumeric(os.listdir(frames_dir))):\n",
        "\t\timage = Image.open(frames_dir+filename)\n",
        "\t\tnew_image = image.resize((1920, 1024))\n",
        "\t\tnew_image.save(resized_frames_dir+str(count)+'.jpg')\n",
        "\t\tprint(image.size) # Output: (1200, 776)\n",
        "\t\tprint(new_image.size) # Output: (400, 400)\n",
        "\t\t\n",
        "\t\t# rename() function will \n",
        "\t\t# rename all the files \n",
        "\t\t \n",
        "\n",
        "# Driver Code \n",
        "if __name__ == '__main__': \n",
        "\t\n",
        "\t# Calling main() function \n",
        "\tmain() \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n",
            "(1920, 1080)\n",
            "(1920, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7doJwidh__2"
      },
      "source": [
        "## **Vehicle Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg6PKLFxqMIy"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/Sproj2/vehicle-yolov3_9500.weights' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seZDuRX_nleX",
        "outputId": "9d2d219f-c79e-48fa-e649-633d61491679"
      },
      "source": [
        "%%writefile /content/vehicle-yolov3.cfg\n",
        "[net]\n",
        "# Testing\n",
        "# batch=64\n",
        "subdivisions=8\n",
        "# Training\n",
        "batch=24\n",
        "subdivisions=2\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.001\n",
        "burn_in=1000\n",
        "max_batches = 500200\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=16\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "###########\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=36\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes=7\n",
        "num=6\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 8\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=36\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes=7\n",
        "num=6\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/vehicle-yolov3.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTLPsTQKw3bp"
      },
      "source": [
        "# Load Yolo\n",
        "load_dir='/content/'\n",
        "yolo_net = cv2.dnn.readNet( load_dir + \"vehicle-yolov3_9500.weights\", load_dir + \"vehicle-yolov3.cfg\")\n",
        "\n",
        "layer_names = yolo_net.getLayerNames()\n",
        "\n",
        "output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIEsZBS6xyJ_"
      },
      "source": [
        "# Object Name\n",
        "classes = [\"Bike\",\"Bus\",\"Car\",\"MiniBus\",\"MiniTruck\",\"Rickshaw\",\"Truck\"]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "383nitCUx5wr"
      },
      "source": [
        "# This will create a text file containing cordinates of bounding boxes of vehicles to be used for counting.\n",
        "def Object_Detection(img,count,f,f2):\n",
        "    \n",
        "    # for key in list(current_frame.keys()):\n",
        "        \n",
        "    begin = time.time() \n",
        "    \n",
        "    # Image \n",
        "    # img = current_frame[key]\n",
        "    height, width, channels = img.shape\n",
        "    # print(height,width,channels)\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    yolo_net.setInput(blob)\n",
        "    outs = yolo_net.forward(output_layers)\n",
        "\n",
        "    # Showing informations on the screen\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = [] \n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.8:\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                # for i in range(15):\n",
        "                #   rand_point_x=random.randint(x,x+w)\n",
        "                #   rand_point_y=random.randint(y,y+h)\n",
        "                #   f.write(str(rand_point_x)+' '+str(rand_point_y) + ' ')\n",
        "                label=classes[class_id]\n",
        "                f.write('{} {} {} {} {} '.format(x,y,w,h,label))\n",
        "                f2.write('{} {} ').format(center_x,center_y)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "    f.write('\\n')\n",
        "    f2.write('\\n')\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    font = cv2.ACCESS_MASK\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            color = colors[class_ids[i]]\n",
        "            # cv2.putText(img,'x',(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,color = (255, 0, 0))\n",
        "            # cv2.putText(img,'x',(x+w,y+h),cv2.FONT_HERSHEY_SIMPLEX,1,color = (255, 0, 0))\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0,0,255), 1)\n",
        "            cv2.putText(img, label+ str(np.around(confidences[i],2)*100) + \"%\", (x, y-5), font, 0.4, (0,0,255), 1)\n",
        "\n",
        "    # cv2.imshow(key, img)\n",
        "    # print(key)\n",
        "    cv2.imwrite(results_dir+str(count)+'.jpg',img)\n",
        "    cv2.waitKey(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlTizPr0wMZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522a50b9-e1c3-4b6b-ff79-105d39060189"
      },
      "source": [
        "import time\n",
        "t0=time.time()\n",
        "count=0\n",
        "f=open('cords_gulberg_night.txt','w')\n",
        "f2=open('center_cords_gulberg_night.txt','w')\n",
        "!mkdir '/content/results_night_gulberg'\n",
        "for i,item in enumerate(sorted_alphanumeric(os.listdir(resized_frames_dir))):\n",
        "  img=cv2.imread(resized_frames_dir+item)\n",
        "  Object_Detection(img,count,f,f2)\n",
        "  count+=1\n",
        "f.close()\n",
        "f2.close()\n",
        "t1=time.time()\n",
        "total_time=t1-t0\n",
        "print(total_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/results_night_gulberg’: File exists\n",
            "95.30381274223328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8MSH-m8zAA9"
      },
      "source": [
        "!zip -r 'frames_night_gulberg.zip' '/content/resized_night_gulberg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1yTMY_vjA2d"
      },
      "source": [
        "# **Vehicle Counting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r93T5uwW0veV"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyUA5t2GzZFR"
      },
      "source": [
        "The function below reads the cordinates of the ends of the two lines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfJ3ymtpQFc4"
      },
      "source": [
        "frames_dir='./frames_gulberg_day/content/resized_day_gulberg/'\n",
        "line_cords_dir='./line_cords_day_gulberg.txt'\n",
        "vehicle_cords_dir='./cords_gulberg_day.txt'\n",
        "results_dir='./results_gulberg_day_updated/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_QkV7W2zWbo"
      },
      "source": [
        "def read_line_cords(f):\n",
        "    cords=f.read().split('\\n')\n",
        "    line_cords=[]\n",
        "    for i in range(len(cords)):\n",
        "      cords[i]=cords[i].split()\n",
        "    for i in range(len(cords)):\n",
        "      if i==len(cords)-1:\n",
        "        break\n",
        "      if i%2==0:\n",
        "        line_cords.append(cords[i:i+2])\n",
        "    return line_cords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvJCVOu90kgp"
      },
      "source": [
        "# This function checks if the point lies within the two lines. Returns 1 if true, else returns 0\n",
        "def check_insider(cords,line_cords):\n",
        "    x,y=cords\n",
        "    y1,y2=line_cords\n",
        "    y1=int(y1)\n",
        "    y2=int(y2)\n",
        "\n",
        "     \n",
        "    if y<y1 and y>y2:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsDrwHaf0yta"
      },
      "source": [
        "# make_flow function is used to read flo file and returns numpy array\n",
        "def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    # print(width)\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    # print(height)\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVMHbwCjaRq5"
      },
      "source": [
        "def count_classes(label,count_c):\n",
        "  if label=='Bike':\n",
        "    count_c[0]+=1\n",
        "  elif label=='Car':\n",
        "    count_c[1]+=1\n",
        "  elif label=='Truck':\n",
        "    count_c[4]+=1\n",
        "  elif label=='Rickshaw':\n",
        "    count_c[5]+=1\n",
        "  elif label=='Bus':\n",
        "    count_c[6]+=1\n",
        "  return count_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNNVbV46jIn1"
      },
      "source": [
        "# From flownet code\n",
        "# Read the flowframe and return numpy array\n",
        "\n",
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)\n",
        "\n",
        "\n",
        "\n",
        "def read_coords(filename):\n",
        "    count_c=[[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0]]\n",
        "    f=open(filename,'r')\n",
        "    line_cords_filename=line_cords_dir\n",
        "    f2=open(line_cords_filename,'r')\n",
        "    line_cords=read_line_cords(f2)\n",
        "    images_coords=f.read().split('\\n')\n",
        "    car_cords=[]\n",
        "    cars_dict={}\n",
        "    all_image_vel_x=[]\n",
        "    all_image_vel_y=[]\n",
        "    image_names=sorted_alphanumeric(os.listdir(frames_dir))\n",
        "    # count=0\n",
        "    for i in range(len(images_coords)-1):\n",
        "      img=cv2.imread(frames_dir+image_names[i])\n",
        "      for k in range(len(line_cords)):\n",
        "        count=0\n",
        "        pix_y=30+(k*50)\n",
        "        print('image',img.shape)\n",
        "        points_arr=images_coords[i].split()\n",
        "        all_car_vel_x=[]\n",
        "        all_car_vel_y=[]\n",
        "        for j in range(1,len(points_arr)+1):\n",
        "            if j%5!=0:\n",
        "                car_cords.append(points_arr[j-1])\n",
        "            else:\n",
        "                car_cords.append(points_arr[j-1])\n",
        "                sin_car_vel_x=[]\n",
        "                sin_car_vel_y=[]\n",
        "                check=[]\n",
        "                num=0\n",
        "                for x in range(50):\n",
        "                    # rand_point_x=1930\n",
        "                    # while rand_point_x > 1920:\n",
        "                    if (int(car_cords[0])+int(car_cords[2]) > 1920) or (int(car_cords[1])+int(car_cords[3])>1024):\n",
        "                        num+=1\n",
        "                        continue\n",
        "                    else:\n",
        "                        rand_point_x=random.randint(round(int(car_cords[1])+((0.40)*int(car_cords[3]))),round(int(car_cords[1])+((0.60)*int(car_cords[3]))))\n",
        "                        rand_point_y=random.randint(round(int(car_cords[0])+((0.20)*int(car_cords[2]))),round(int(car_cords[0])+((0.80)*int(car_cords[2]))))\n",
        "                        check.append(check_insider((rand_point_y,rand_point_x),(line_cords[k][0][1],line_cords[k][1][1])))\n",
        "                        # print(check_insider((rand_point_y,rand_point_x),(line_cords[k][0][1],line_cords[k][0][1])))\n",
        "                        if check_insider((rand_point_y,rand_point_x),(line_cords[k][0][1],line_cords[k][1][1])):\n",
        "                            img=cv2.circle(img,(rand_point_y,rand_point_x),4,(255,0,0),3)\n",
        "\n",
        "\n",
        "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                fontScale = 1.2\n",
        "                color=(255,255,255)\n",
        "\n",
        "                sum_check=sum(check)/50\n",
        "                if sum_check>0.45:\n",
        "                    count+=1\n",
        "                    count_c[k]=count_classes(car_cords[4],count_c[k])\n",
        "                      \n",
        "\n",
        "                    \n",
        "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                fontScale = 1.2\n",
        "                img=cv2.putText(img,car_cords[4],(round(int(car_cords[0])+(0.25)*int(car_cords[2])),round(int(car_cords[1])+(0.25)*int(car_cords[3])+35)),font,fontScale,color = (255, 0, 0))\n",
        "                \n",
        "                img=cv2.rectangle(img,((round(int(car_cords[0])+(0.20)*int(car_cords[2])),round(int(car_cords[1])+(0.40)*int(car_cords[3])))),(round(int(car_cords[0])+(0.80)*int(car_cords[2])),round(int(car_cords[1])+(0.60)*int(car_cords[3]))),(255, 0, 0),1)\n",
        "                img=cv2.rectangle(img,(int(car_cords[0]),int(car_cords[1])),(int(car_cords[0])+int(car_cords[2]),int(car_cords[1])+int(car_cords[3])),(255, 0, 0),1)\n",
        "                car_cords=[]\n",
        "\n",
        "        color=(172,172,172)\n",
        "        color=(255,255,255)\n",
        "        image=cv2.line(img,(int(line_cords[k][0][0]),int(line_cords[k][0][1])),(int(line_cords[k][0][2]),int(line_cords[k][0][3])),(0,0,255),5)\n",
        "        image=cv2.line(img,(int(line_cords[k][1][0]),int(line_cords[k][1][1])),(int(line_cords[k][1][2]),int(line_cords[k][1][3])),(0,0,255),5)\n",
        "        \n",
        "        image=cv2.putText(image,f'Car: {count_c[k][1]}',(100,pix_y),font,fontScale,color = color,thickness=2)\n",
        "        image=cv2.putText(image,f'Bike: {count_c[k][0]}',(350,pix_y),font,fontScale,color = color,thickness=2)\n",
        "        image=cv2.putText(image,f'Rickshaw: {count_c[k][5]}',(600,pix_y),font,fontScale,color = color,thickness=2)\n",
        "        image=cv2.putText(image,f'Bus: {count_c[k][6]}',(850,pix_y),font,fontScale,color = color,thickness=2)\n",
        "        image=cv2.putText(image,f'Truck: {count_c[k][4]}',(1050,pix_y),font,fontScale,color = color,thickness=2)\n",
        "        \n",
        "      cv2.imwrite(results_dir+str(i)+'.jpg',image)      \n",
        "    return count,count_c\n",
        "# velx,vely,count=read_coords('/content/cords_600.txt')\n",
        "count,count_c=read_coords(vehicle_cords_dir)\n",
        "avg=(np.array(count_c[0])+np.array(count_c[1]))\n",
        "print(avg)\n",
        "\n",
        "# print('x: ',velx)\n",
        "# print('y: ',vely)\n",
        "print(count)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9C8H57IZrvj"
      },
      "source": [
        "# **Vehicle Velocity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDvb6FmLZyg0"
      },
      "source": [
        "First you need to run lin_interpol.py on the desktop , since cv2.EVENT_LBUTTONDOWN does not work on google colab. You need to manually mark the road segment and two lines on the image representing same actual length, this will create a text file named (text_speed.txt) which will be further used in the code below to convert speed in pixels per frames to km/h.\n",
        "\n",
        "You Also need to run FlowNet.ipynb to get flow frames\n",
        "\n",
        "**Copy the text file generated to /content/ and proceed further** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JchvCVX2bE_a"
      },
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from kneed import KneeLocator\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg6criL1bJqi"
      },
      "source": [
        "flow_frames_dir=\"./Real Speed Calc Content/flowframes/\"\n",
        "frames_dir=\"./Real Speed Calc Content/frames/\"\n",
        "vehicle_cords_dir=\"./Real Speed Calc Content/cords.txt\"\n",
        "text_speed_dir=\"./Real Speed Calc Content/text_speed.txt\"\n",
        "output_dir=\"./Real Speed Calc Content/output_frames/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYQ9LmsOc3aA"
      },
      "source": [
        "total_total = 0\n",
        "\n",
        "def check_lengths_frames_text():\n",
        "    text_cords = open(vehicle_cords_dir, 'r')\n",
        "    text_cords = text_cords.read().split(\"\\n\")\n",
        "\n",
        "    len_cords_lines = len(text_cords)\n",
        "\n",
        "    flowframes_dir = os.listdir(flowframes_dir)\n",
        "    len_flowframes = len(flowframes_dir)\n",
        "\n",
        "    frame_dir = os.listdir(frames_dir)\n",
        "    len_frames = len(frame_dir)\n",
        "\n",
        "    print(len_cords_lines, len_flowframes, len_frames)\n",
        "\n",
        "    if len_cords_lines == len_flowframes == len_frames:\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxdHkky_dE8L"
      },
      "source": [
        "def read_speed():\n",
        "    global normalize_meters, coordinate_p1, p1_pixels, p2_pixels, z, midline_eq\n",
        "\n",
        "    text_speed = open(text_speed_dir, 'r')\n",
        "    text_speed = text_speed.read()\n",
        "\n",
        "    # Text Speed assigning\n",
        "    text_speed = text_speed.split(\"\\n\")\n",
        "\n",
        "    normalize_meters = float(text_speed[0])\n",
        "\n",
        "    coordinate_p1 = text_speed[1].split(\" \")\n",
        "    coordinate_p1[0] = int(coordinate_p1[0])\n",
        "    coordinate_p1[1] = int(coordinate_p1[1])\n",
        "\n",
        "    p1_pixels = float(text_speed[2])\n",
        "    p2_pixels = float(text_speed[3])\n",
        "\n",
        "    z = float(text_speed[4])\n",
        "\n",
        "    temp_midline_eq = text_speed[5].split(\" \")\n",
        "    midline_eq = float(temp_midline_eq[0]), float(temp_midline_eq[1])\n",
        "\n",
        "    # print(normalize_meters)\n",
        "    # print(coordinate_p1)\n",
        "    # print(z)\n",
        "\n",
        "# Read all text files\n",
        "def read_points():\n",
        "    global points\n",
        "\n",
        "    # Read text files\n",
        "    \n",
        "    text_cords = open(vehicle_cords_dir, 'r')\n",
        "    text_cords = text_cords.read()\n",
        "\n",
        "    text_cords = text_cords.split(\"\\n\")\n",
        "\n",
        "    # Text Coordinates assigning\n",
        "    points = []\n",
        "    for line in text_cords:\n",
        "        points.append(line)\n",
        "\n",
        "    # text_cords = text_cords.split()\n",
        "    # for i in range(0, len(text_cords)-1, 2):\n",
        "    #     points.append([int(text_cords[i]), int(text_cords[i+1])])\n",
        "\n",
        "def find_points_line(i):\n",
        "    global points, points_line\n",
        "\n",
        "    points_line = []\n",
        "\n",
        "    points_string = points[i]\n",
        "\n",
        "    if points_string == '':\n",
        "        return False\n",
        "\n",
        "    points_string = points_string.split(\" \")\n",
        "\n",
        "    for i in range(0, len(points_string)-1, 2):\n",
        "        points_line.append([int(points_string[i]), int(points_string[i+1])])\n",
        "\n",
        "    return True\n",
        "\n",
        "# Find the number of pixels representing each point\n",
        "def find_number_pixels():\n",
        "    global number_pixels, points_line, coordinate_p1, z, midline_eq\n",
        "\n",
        "    if midline_eq[0] != 0:\n",
        "        midline_grad_inv = -1 / midline_eq[0]\n",
        "    else:\n",
        "        midline_grad_inv = 99999999999999\n",
        "\n",
        "    number_pixels = []\n",
        "\n",
        "    for point in points_line:\n",
        "        midline_point = find_shortest_midline(point, midline_grad_inv)\n",
        "        length_new = pytha(midline_point, coordinate_p1)\n",
        "        \n",
        "        # length_new = pytha(point, coordinate_p1)\n",
        "\n",
        "        # Normalize\n",
        "        alpha = length_new / z\n",
        "\n",
        "        # Put in formula for number of pixels\n",
        "        number_pixels.append(formula(alpha) * z)\n",
        "        \n",
        "# Find speed of each point\n",
        "def find_speed(flow,frame_name):\n",
        "    global points_line, number_pixels, speed, velocity\n",
        "\n",
        "    speed = []\n",
        "    velocity = []\n",
        "    img=cv2.imread(frame_name)\n",
        "    # Read flow\n",
        "    flo = read_flow(flow)\n",
        "    flow = make_flow(flo) # Contains numpy array of velocity values.\n",
        "    flo.close()\n",
        "    flow = np.transpose(flow, (1, 0, 2))\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
        "\n",
        "    for i in range(0, len(points_line)):\n",
        "        velocity.append(flow[points_line[i][0]][points_line[i][1]])\n",
        "        value = find_speed_single(flow[points_line[i][0]][points_line[i][1]], number_pixels[i])\n",
        "        speed.append(value)\n",
        "        img=cv2.putText(img,\"{:.2f}\".format(value*3.6),(points_line[i][0],points_line[i][1]), font, 0.7, (0,0,0), 2)\n",
        "        cv2.imwrite(output_dir + frame_name.split(\"/\")[-1], img)\n",
        "        cv2.imshow('image',img)\n",
        "    # print(\"\\nAll Speed:\", speed)\n",
        "\n",
        "# Find resultant speed of a vector\n",
        "def find_speed_single(velocity, number_pixel):\n",
        "    global normalize_meters\n",
        "    final_velocity = ((velocity[0] ** 2) + (velocity[1] ** 2)) ** 0.5\n",
        "    # final_velocity = 22\n",
        "\n",
        "    frame_second = 6\n",
        "\n",
        "    return((final_velocity*frame_second / number_pixel) * normalize_meters)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwsFWunbZvzu"
      },
      "source": [
        "# Clustering\n",
        "def cluster():\n",
        "    global speed, velocity, points_line\n",
        "\n",
        "    clusters = 4\n",
        "\n",
        "    velocity = np.array(velocity)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(velocity)\n",
        "\n",
        "    kmeans = KMeans(\n",
        "        init=\"random\",\n",
        "        n_clusters=clusters,\n",
        "        n_init=10,\n",
        "        max_iter=300,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    kmeans.fit(scaled_features)\n",
        "\n",
        "    kmeans.inertia_\n",
        "\n",
        "    kmeans.cluster_centers_\n",
        "\n",
        "    kmeans.n_iter_\n",
        "\n",
        "\n",
        "    # velocity_labels = [[], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    # points_labels = [[], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    # speed_labels = [[], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    velocity_labels = [[], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    points_labels = [[], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    speed_labels = [[], [], [], [], []] # Starts from top and goes clockwise. Contains the points.\n",
        "    average_speed = []\n",
        "\n",
        "    for i, val in enumerate(kmeans.labels_):\n",
        "        label = int(val)\n",
        "        velocity_labels[label-1].append(velocity[i])\n",
        "        points_labels[label-1].append(points_line[i])\n",
        "        speed_labels[label-1].append(speed[i])\n",
        "\n",
        "        for i in range(0, len(speed_labels)):\n",
        "            average_speed.append((average(speed_labels[i], len(points_line)), len(speed_labels[i])))\n",
        "            # print(\"Average of \", i, \"is:\", average(speed_labels[i], len(points_line)), \"for\", len(speed_labels[i]), \"people.\")\n",
        "\n",
        "    return points_labels, velocity_labels, speed_labels, average_speed\n",
        "\n",
        "def cluster_2():\n",
        "    global velocity, speed, points_line, total_total\n",
        "\n",
        "    velocity_labels = [[], [], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points. Last is less than X speed.\n",
        "    points_labels = [[], [], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points. Last is less than X speed.\n",
        "    speed_labels = [[], [], [], [], [], [], [], [], []] # Starts from top and goes clockwise. Contains the points. Last is less than X speed.\n",
        "    average_speed = [] # Average speed of each cluster with its number of people\n",
        "    total_average_speed = 0 # The avg speed of the whole crowd\n",
        "\n",
        "    for i, vel in enumerate(velocity):\n",
        "        print(\"\\nVelocity:\", vel)\n",
        "        quadrant = check_quadrant(vel)\n",
        "        print(\"Quadrant:\", quadrant)\n",
        "        line_eq = make_line_eq(vel)\n",
        "        print(\"LineEq:\", line_eq)\n",
        "        degree = find_degree(line_eq[0])\n",
        "        print(\"Degree:\", degree)\n",
        "        print(\"Speed:\", speed[i])\n",
        "        label = check_label(quadrant, degree, speed[i]) # Check quadrant and degree for position. Check speed if less than X.\n",
        "        print(\"Final Label:\", label)\n",
        "\n",
        "        velocity_labels[label-1].append(velocity[i])\n",
        "        points_labels[label-1].append(points_line[i])\n",
        "        speed_labels[label-1].append(speed[i])\n",
        "    \n",
        "    for i in range(0, len(speed_labels)):\n",
        "        average_speed.append((average(speed_labels[i], len(speed_labels[i])), len(speed_labels[i])))\n",
        "        total_average_speed += average_speed[i][0]\n",
        "        print(\"Average of \", i, \"is:\", average_speed[i][0], \"for\", average_speed[i][1], \"people.\")\n",
        "\n",
        "    # total_average_speed = total_average_speed / len(points_line)\n",
        "    total_average_speed = total_average_speed\n",
        "    total_total += total_average_speed\n",
        "\n",
        "    return points_labels, velocity_labels, speed_labels, average_speed, total_average_speed\n",
        "    \n",
        "def output_arrows(i, frame_name, clustered_points, clustered_velocity, clustered_speed, average_speed, total_average_speed):\n",
        "    global points_line\n",
        "\n",
        "    # Draw arrows\n",
        "    print(frame_name)\n",
        "    img = cv2.imread(frame_name)\n",
        "\n",
        "\n",
        "    colors = [(90,90,90), (0,255,0), (0,0,255), (255,255,0), (0,255,255), (255,0,255), (255,255,255), (100,100,140), (255,0,0)]\n",
        "\n",
        "    for i in range(0, len(clustered_points)):\n",
        "        for j in range(0, len(clustered_points[i])):\n",
        "            x = clustered_points[i][j][0]\n",
        "            y = clustered_points[i][j][1]\n",
        "\n",
        "            new_cord = (int(x + clustered_velocity[i][j][0]), int(y + clustered_velocity[i][j][1])) # Get new coordinate\n",
        "\n",
        "            # Multiple length of coordinate with speed to get length of arrow\n",
        "            distance = pytha(new_cord, (x, y))\n",
        "            # print(\"\\nDistance:\", distance)\n",
        "\n",
        "            if distance != 0:\n",
        "\n",
        "                greater_distance = distance * clustered_speed[i][j] * 2\n",
        "                # print(\"Greater Distance:\", greater_distance)\n",
        "\n",
        "                # Get new coordinates after speed multiplication\n",
        "                ratio = greater_distance / distance\n",
        "                # ratio = ratio / \n",
        "                # print(\"Ratio:\", ratio)\n",
        "                \n",
        "                x_final = x + int((new_cord[0] - x) * ratio)\n",
        "                y_final = y + int((new_cord[1] - y) * ratio)\n",
        "\n",
        "                new_cord = (x_final, y_final)\n",
        "\n",
        "            color = colors[int(i)]\n",
        "            # print(\"color:\", color)\n",
        "            cv2.arrowedLine(img, (x,y), new_cord, color, 3)\n",
        "\n",
        "    img = cv2.copyMakeBorder(img, 180, 0, 0, 0, cv2.BORDER_CONSTANT, None, (0, 0, 0))\n",
        "\n",
        "    arrow_directions_text = [\"T\", \"TR\", \"R\", \"BR\", \"B\", \"BL\", \"L\", \"TL\", \"S\"]\n",
        "    \n",
        "    # Add text\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
        "    for i, color in enumerate(colors):\n",
        "            factor_arrow = int((i + 2.5) * 115) - 205\n",
        "            factor_speed = int((i + 2) * 115) - 195\n",
        "            factor_count = int((i + 2) * 115) - 195\n",
        "            \n",
        "            cv2.putText(img, arrow_directions_text[i], (factor_arrow-8, 30), font, 1, color, 2)\n",
        "            cv2.arrowedLine(img, (factor_arrow, 100), (factor_arrow, 50), color, 6, tipLength = 0.3)\n",
        "            cv2.putText(img, str(round(average_speed[i][0], 1)) + \" m/s\", (factor_speed, 130), font, 0.7, color, 2)\n",
        "            cv2.putText(img, str(average_speed[i][1]) + \" ppl\", (factor_count, 160), font, 0.7, color, 2)\n",
        "\n",
        "    cv2.putText(img, \"Avg Speed: \" + str(round(total_average_speed, 2)), (1080, 100), font, 0.7, (255,255,255), 2)\n",
        "    cv2.putText(img, \"Total Ppl:  \" + str(len(points_line)), (1080, 150), font, 0.7, (255,255,255), 2)\n",
        "\n",
        "    # Write image\n",
        "    print(img.shape)\n",
        "    # cv2.imwrite(\"./Real Speed Calc Content/output_frames/\" + frame_name.split(\"/\")[-1], img)\n",
        "\n",
        "    # Display image\n",
        "    # cv2.imshow('image', img)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Helper Functions\n",
        "\n",
        "def find_shortest_midline(point, midline_grad_inv):\n",
        "    global midline_eq\n",
        "\n",
        "    midline_y_inv = point[0]-midline_grad_inv\n",
        "\n",
        "    x = (midline_y_inv - midline_eq[1]) / (midline_eq[0] - midline_grad_inv)\n",
        "    y = (x * midline_eq[0]) + midline_eq[1]\n",
        "\n",
        "    return (x, y)\n",
        "\n",
        "\n",
        "def check_quadrant(vel):\n",
        "    if vel[0] > 0: # Positive X\n",
        "        if vel[1] > 0: # Positive Y\n",
        "            return 3\n",
        "        else:\n",
        "            return 1\n",
        "    else: # Negative X\n",
        "        if vel[1] > 0: # Positive Y\n",
        "            return 4\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "def make_line_eq(vel):\n",
        "    gradient = vel[1] / vel[0]\n",
        "    y_intercept = vel[1] - (vel[0] * gradient)\n",
        "    \n",
        "    return (gradient, y_intercept)\n",
        "\n",
        "def find_degree(gradient):\n",
        "    return abs(math.degrees(math.atan(gradient)))\n",
        "\n",
        "def check_label(quadrant, degree, speed):\n",
        "    if speed <= 0.1:\n",
        "        return 9\n",
        "\n",
        "    if quadrant == 1:\n",
        "        if degree <= 22.5:\n",
        "            return 3\n",
        "        elif degree <= 67.5:\n",
        "            return 2\n",
        "        elif degree <= 90:\n",
        "            return 1\n",
        "        else:\n",
        "            print(\"Error in degree quadrant 1\")\n",
        "    elif quadrant == 2:\n",
        "        if degree <= 22.5:\n",
        "            return 7\n",
        "        elif degree <= 67.5:\n",
        "            return 8\n",
        "        elif degree <= 90:\n",
        "            return 1\n",
        "        else:\n",
        "            print(\"Error in degree quadrant 2\")\n",
        "    elif quadrant == 3:\n",
        "        if degree <= 22.5:\n",
        "            return 3\n",
        "        elif degree <= 67.5:\n",
        "            return 4\n",
        "        elif degree <= 90:\n",
        "            return 5\n",
        "        else:\n",
        "            print(\"Error in degree quadrant 3\")\n",
        "    elif quadrant == 4:\n",
        "        if degree <= 22.5:\n",
        "            return 7\n",
        "        elif degree <= 67.5:\n",
        "            return 6\n",
        "        elif degree <= 90:\n",
        "            return 5\n",
        "        else:\n",
        "            print(\"Error in degree quadrant 4\")\n",
        "    else:\n",
        "        print(\"No quadrant found\")\n",
        "\n",
        "# Formula from sir\n",
        "def formula(alpha):\n",
        "    global p1_pixels, p2_pixels, z\n",
        "    return ((1 - alpha) * (p1_pixels / z)) + (alpha * (p2_pixels / z))\n",
        "\n",
        "# Pythagoras\n",
        "def pytha(point1, point2):\n",
        "    diff_y = (point1[0] - point2[0])**2\n",
        "    diff_x = (point1[1] - point2[1])**2\n",
        "    return (diff_x + diff_y)**0.5\n",
        "\n",
        "# From flownet code\n",
        "def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow\n",
        "\n",
        "def read_flow(flow):\n",
        "    return open(flow_frames_dir+flow, \"r\") \n",
        "\n",
        "def average(values, length):\n",
        "    print(\"Values:\", values)\n",
        "    print(\"Length:\", length)\n",
        "    num = sum(values)\n",
        "    if length == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return num / length\n",
        "\n",
        "# Copy frame\n",
        "def copy_frame(frame):\n",
        "    shutil.copyfile(frame,output_dir + frame.split(\"/\")[-1])\n",
        "\n",
        "def main():\n",
        "    global normalize_meters, number_pixels, coordinate_p1, p1_pixels, p2_pixels, z, points, speed, velocity, points_line, midline_eq, total_total\n",
        "\n",
        "    read_speed()\n",
        "    read_points()\n",
        "    if not check_lengths_frames_text():\n",
        "        print(\"Lengths of frames, flowframes and coordinate text file does not match\")\n",
        "    \n",
        "    for i, flow in enumerate(sorted(os.listdir(flow))):\n",
        "        frame_name = frames_dir + flow[0:-4] + \".jpg\"\n",
        "\n",
        "        if not find_points_line(i): # Get the line points\n",
        "            copy_frame(frame_name)\n",
        "            continue\n",
        "        find_number_pixels() # Get the pixels of each point in the line\n",
        "        find_speed(flow,frame_name) # Find speed\n",
        "        \n",
        "        points_labels, velocity_labels, speed_labels, average_speed, total_average_speed = cluster_2()\n",
        "        output_arrows(i, frame_name, points_labels, velocity_labels, speed_labels, average_speed, total_average_speed)\n",
        "        # clustered_points, clustered_velocity = cluster() # Cluster and output average speed\n",
        "        # output_arrows(i, clustered_points, clustered_velocity)\n",
        "\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    print(total_total)\n",
        "\n",
        "# driver function \n",
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}